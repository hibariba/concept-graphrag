{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 1. Why LLM output is non-deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# hardware based sotchasticity\n",
    "every time we add together floating-point numbers in a different order, we can get a completely different result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "vals = [1e-10, 1e-5, 1e-2, 1]\n",
    "vals = vals + [-v for v in vals]\n",
    "\n",
    "results = []\n",
    "random.seed(42)\n",
    "for _ in range(10000):\n",
    "    random.shuffle(vals)\n",
    "    results.append(sum(vals))\n",
    "\n",
    "results = sorted(set(results))\n",
    "print(f\"There are {len(results)} unique results: {results}\")\n",
    "\n",
    "# Output:\n",
    "# There are 102 unique results: [-8.326672684688674e-17, -7.45931094670027e-17, ..., 8.326672684688674e-17]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Sampling and logits\n",
    "\n",
    "### inference-time logits\n",
    "\n",
    "`My favorite color is ...`\n",
    "\n",
    "<img src=\"https://huyenchip.com/assets/pics/sampling/2-logits.png\" style=\"width:40%;\">\n",
    "\n",
    "\n",
    "### sampling\n",
    "\n",
    "- Temperature\n",
    "- TopK\n",
    "- TopP\n",
    "\n",
    "<img src=\"https://huyenchip.com/assets/pics/sampling/4-logprobs.png\" style=\"width:75%;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print infernce logit table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Real cause of nondeterminins: batch size variation\n",
    "- [Defeating Nondeterminism in LLM Inference](https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/)\n",
    "    - batch size variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_default_device('mps')\n",
    "\n",
    "B = 2048\n",
    "D = 4096\n",
    "a = torch.linspace(-1000, 1000, B*D).reshape(B, D)\n",
    "b = torch.linspace(-1000, 1000, D*D).reshape(D, D)\n",
    "# Doing a matrix vector multiplication by taking\n",
    "# the first element of the batch\n",
    "out1 = torch.mm(a[:1], b)\n",
    "# Doing a matrix matrix multiplication and then taking\n",
    "# the first element of the batch\n",
    "out2 = torch.mm(a, b)[:1]\n",
    "print((out1 - out2).abs().max()) # tensor(1669.2500, device='mps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "out2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# 2. bringing order to randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## prompt and prey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## structured output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### trust the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### trust the math:L constrained output\n",
    "\n",
    "<img src=\"https://huyenchip.com/assets/pics/sampling/7-guidance.png\" style=\"width:60%;\">\n",
    "\n",
    "#### structured outputs\n",
    "\n",
    "<img src=\"https://huyenchip.com/assets/pics/sampling/8-finetuning-classifier.png\" style=\"width:60%;\">\n",
    "\n",
    "#### Constraint sampling\n",
    "\n",
    "<img src=\"https://huyenchip.com/assets/pics/sampling/9-constrained-sampling.png\" style=\"width:60%;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict tokens: outlines \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# 3. Grounding inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## bloating context\n",
    "adding raw source information to inferance context\n",
    "- context sizes\n",
    "- ignoring middle of the context\n",
    "- garbage in garbage out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## semantic rethrieval: RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "when it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "when it dos not works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## tree-based rethrieval (DAG): Traversing Abstract Syntax Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AST example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why not repo map example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## graph basd rethrieval (incuding Cyclic and Undirrected): GraphRAG\n",
    "- [From Local to Global: A Graph RAG Approach to Query-Focused Summarization](https://arxiv.org/abs/2404.16130)\n",
    "- [github graphrag](https://github.com/microsoft/graphrag)\n",
    "- <img src=\"assets/graphrag_image1.png\" style=\"width:60%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "# 4. Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Creating Basic Knowledge Graph (Neo4j)\n",
    "\n",
    "### Core Components\n",
    "\n",
    "1. **Nodes (entities):** Represent data objects with labels and properties[1][2]\n",
    "2. **Relationships:** Connect nodes with directional connections and properties[2]\n",
    "3. **Properties:** Key-value pairs attached to nodes or relationships[2]\n",
    "\n",
    "### Data Model Structure\n",
    "\n",
    "**Nodes:**\n",
    "- Securities (stocks, bonds, derivatives)\n",
    "- Companies/Issuers\n",
    "- Exchanges\n",
    "- Economic indicators\n",
    "- News articles\n",
    "- Analysts[3][4]\n",
    "\n",
    "**Relationships:**\n",
    "- Company -[:TRADES_ON]-> Exchange\n",
    "- Security -[:ISSUED_BY]-> Company\n",
    "- Company -[:OWNS]-> Company (ownership stakes)\n",
    "- Security -[:CORRELATES_WITH]-> Security\n",
    "- News -[:MENTIONS]-> Company[3]\n",
    "\n",
    "### Transformation Steps\n",
    "\n",
    "1. **Extract identifiers:** Convert tickers, ISINs, CUSIPs to Security nodes with standardized properties\n",
    "2. **Map hierarchies:** Model corporate structures, sector classifications, and geographic relationships as graph relationships\n",
    "3. **Connect market** Link securities to exchanges, pricing data, and trading volumes with temporal properties\n",
    "4. **Integrate meta** Transform metadata fields into node properties and create relationships for derived data (correlations, risk factors)\n",
    "5. **Add lineage:** Track data provenance and transformations for compliance\n",
    "\n",
    "## Domain Graph\n",
    "\n",
    "<img src=\"https://graphrag.com/_astro/domain-graph.DOzUcy6K_YkdvU.svg\" style=\"width:90%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Using LLM to Update Knowledge Graph from Unstructured Text\n",
    "\n",
    "### Extraction Pipeline\n",
    "\n",
    "1. **Chunk and embed text:** Split articles/papers into smaller text chunks (500-1000 tokens), generate embeddings for each chunk, and store as Document and Chunk nodes[1][2]\n",
    "\n",
    "2. **Entity extraction with schema:** Use LLM with prompt specifying allowed node types from Bloomberg model (Company, Security, Exchange, Economic_Indicator, Pattern) and extract entities with properties[3][2][4]\n",
    "\n",
    "3. **Relationship extraction:** Prompt LLM to identify relationships between extracted entities and return structured JSON output[1][4]\n",
    "\n",
    "4. **Entity disambiguation:** Use LLM to merge duplicate entities (e.g., \"NVIDIA\" vs \"Nvidia Corp\" vs \"NVDA\") by matching on identifiers and properties[1]\n",
    "\n",
    "### LLM Prompt Example\n",
    "\n",
    "**For tech company article extraction:**\n",
    "```\n",
    "Extract entities and relationships from this text about technology companies.\n",
    "\n",
    "Entity types: Company, Security, Product, Pattern, Market_Trend\n",
    "Relationship types: PRODUCES, COMPETES_WITH, EXHIBITS_PATTERN, CORRELATES_WITH\n",
    "\n",
    "Text: \"NVIDIA's GPU shipments showed 40% growth correlation with Microsoft Azure \n",
    "expansion. The pattern suggests cloud infrastructure demand drives semiconductor sales.\"\n",
    "\n",
    "Output as JSON with: entity_type, name, properties, relationships\n",
    "```\n",
    "\n",
    "### Updating Existing Graph (Cypher Examples)\n",
    "\n",
    "**Merge extracted companies:**\n",
    "```cypher\n",
    "MERGE (c:Company {ticker: 'NVDA'})\n",
    "ON CREATE SET c.name = 'NVIDIA Corporation', c.sector = 'Technology'\n",
    "ON MATCH SET c.lastUpdated = datetime()\n",
    "```\n",
    "\n",
    "**Add observed patterns:**\n",
    "```cypher\n",
    "CREATE (p:Pattern {\n",
    "  id: 'gpu_cloud_correlation',\n",
    "  description: '40% growth correlation',\n",
    "  confidence: 0.85,\n",
    "  source: 'academic_paper_123'\n",
    "})\n",
    "\n",
    "MATCH (nvidia:Company {ticker: 'NVDA'})\n",
    "MATCH (msft:Company {ticker: 'MSFT'})\n",
    "CREATE (nvidia)-[:EXHIBITS_PATTERN]->(p)\n",
    "CREATE (p)-[:CORRELATES_WITH]->(msft)\n",
    "```\n",
    "\n",
    "**Link to source documents:**\n",
    "```cypher\n",
    "MATCH (doc:Document {id: 'article_456'})\n",
    "MATCH (p:Pattern {id: 'gpu_cloud_correlation'})\n",
    "CREATE (p)-[:EXTRACTED_FROM {extractedAt: datetime()}]->(doc)\n",
    "```\n",
    "\n",
    "### Bloomberg Model Extensions\n",
    "\n",
    "**New node types for unstructured content:**\n",
    "- Pattern (observed trends/behaviors)\n",
    "- Research_Finding\n",
    "- Market_Signal\n",
    "- Competitive_Dynamic[5][1]\n",
    "\n",
    "**New relationships:**\n",
    "- Company -[:EXHIBITS_PATTERN]-> Pattern\n",
    "- Pattern -[:CORRELATES_WITH]-> Company\n",
    "- Company -[:COMPETES_WITH {intensity: float}]-> Company\n",
    "- Security -[:SHOWS_SIGNAL]-> Market_Signal\n",
    "- Pattern -[:EXTRACTED_FROM]-> Document\n",
    "\n",
    "\n",
    "## Lexical Graph\n",
    "<img src=\"https://graphrag.com/_astro/knowledge-graph-lexical-graph-extracted-entities.BsKeTZFb_ZxxPUk.svg\" style=\"width:50%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "# 5. LLM + KG\n",
    "\n",
    "\n",
    "## basic pattern:\n",
    "\n",
    "<img src=\"assets/graphrag-diagram.gzIXlJ0V_Z1168rD.svg\" style=\"width:100%;\">\n",
    "\n",
    "### Rethrieval patterns\n",
    "\n",
    "- Basic Retriever\n",
    "- Cypher Templates\n",
    "- Dynamic Cypher Generation\n",
    "- Global Community Summary Retriever\n",
    "- Graph-Enhanced Vector Search\n",
    "- Hypothetical Question Retriever\n",
    "- Local Retriever\n",
    "- Metadata Filtering\n",
    "- Parent-Child Retriever\n",
    "- Pattern Matching\n",
    "- Text2Cypher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
